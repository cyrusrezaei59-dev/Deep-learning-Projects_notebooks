{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3_21_22.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BxtreUAPraI-"},"source":["#**Deep Learning Homework 3: Convolutional Neural Networks**\n","\n","### MSc Computer Science, Data Science, Cybersecurity @UniPD\n","### 2nd semester - 6 ECTS\n","### Prof. Nicol√≤ Navarin & Prof. Alessandro Sperduti\n","---\n","In this homework, we will explore how to develop a simple Convolutional Neural Network for image classification. We will use the CIFAR-10 dataset. In the first part, we will learn how to develop a simple CNN, while in the second part we will explore the impact of various hyper-parameters in the learning performances."]},{"cell_type":"markdown","metadata":{"id":"CRwTPJt3rxug"},"source":["##Exercise 3.1: Simple CNN\n","\n","Let's start by importing Tensorflow, Keras and Numpy"]},{"cell_type":"code","metadata":{"id":"seDcv-RvrUpM"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxWbaR_HsPYp"},"source":["###Load dataset:\n","### Load Data: CIFAR-10 dataset\n","\n","\n","We will use the CIFAR-10 dataset.The dataset consists of 60000 images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. Each sample is a 32x32 pixels color image, associated with a label from 10 classes:\n","\n","```\n","class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n","```\n","\n","Each pixel intensity is represented by a `uint8` (byte) from 0 to 255.\n","We will divide the dataset in training, testing and validation set. As you already know, the training set will be used to train the model, the validation set will be used to perform model selection and finally, the test set will be used to asses the performance of deep network.\n","\n","Since we will use a [2DConv](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) we have to provide also a new dimension of the input that represents the number of channels (that in grey scale image is just one and in color images is 3). Therefore, if you are using grayscale images use [tf.expand_dims](https://www.tensorflow.org/api_docs/python/tf/expand_dims#:~:text=Used%20in%20the%20notebooks,-Used%20in%20the&text=This%20operation%20is%20useful%20to,to%20a%20tensor%20of%20scalars) to transform each image from a matrix to a 3-dimensional tensor. Finally, we have to normalize the input data."]},{"cell_type":"code","metadata":{"id":"8QQy37jnsH_e"},"source":["cifar_10 = keras.datasets.cifar10\n","(X_train_full, y_train_full), (X_test, y_test) = (\n","    cifar_10.load_data()) # The dataset is already divede in test and training\n","\n","# We extract the first 5000 samples of the training set, to use them as the validation set\n","X_valid, X_train = X_train_full[:5000], X_train_full[5000:] \n","y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n","\n","class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n","               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ry-tEvXJGwAW"},"source":["Let's take a look at a sample of the images in the dataset:"]},{"cell_type":"code","metadata":{"id":"4Rj5AvxuG1VK"},"source":["n_rows = 5\n","n_cols = 10\n","plt.figure(figsize=(n_cols * 1.4, n_rows * 1.6))\n","for row in range(n_rows):\n","    for col in range(n_cols):\n","        index = n_cols * row + col\n","        plt.subplot(n_rows, n_cols, index + 1)\n","        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n","        plt.axis('off')\n","        plt.title(class_names[y_train[index][0]])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CauFMlRtG6Pu"},"source":["### [TO COMPLETE] Input Normalization:\n","\n","When using Gradient Descent, it is usually a good idea to ensure that all the features have a similar scale. Try to standardize the pixel values."]},{"cell_type":"code","metadata":{"id":"YxeMtdcbG8y1"},"source":["#[TO COMPLETE]: define X_train_scaled, X_valid_scaled and X_test_scaled, the sets that contains \n","#Hint: For each feature (pixel intensity), you must subtract the mean() of that \n","#feature (across all instances, so use axis=0) and divide by its standard \n","#deviation (std(), again axis=0)\n","\n","\n","X_train = #[TO COMPLETE]\n","X_valid = #[TO COMPLETE]\n","X_test = #[TO COMPLETE]\n","\n","\n","#Add one dimension to manage the channel if you are using grayscale images.\n","#X_train=tf.expand_dims(X_train, 3) \n","#X_valid=tf.expand_dims(X_valid, 3) \n","#X_test=tf.expand_dims(X_test,3)\n","\n","#Make sure you compute the means and standard deviations on the training set,\n","#and use these statistics to scale the training set, the validation set and the\n","# test set"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhWYkFmQsNm5"},"source":["###Define the model\n","\n","Let's create a simple CNN. The model will be composed of:\n","* One 2D convolutional layer with kernel size 3x3 and 32 output filters/features, that use ReLu activation function\n","* a Max Pooling layer (2D) of size 2x2 ([MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D))\n","* a Flatten layer\n","* a final Dense layer with 10 output neurons (one per class), and with the \"softmax\" activation function to ensure that the sum of all the estimated class probabilities for each image is equal to 1.\n","Note that as 'input_shape' attribute's value in the first layer report also the third dimension that represents the channel."]},{"cell_type":"code","metadata":{"id":"paLpCd7XsOYs"},"source":["model = keras.models.Sequential([\n","    keras.layers.Conv2D(filters=32, kernel_size=[3,3], padding=\"same\", activation=\"relu\", input_shape=[32, 32,3]),\n","    keras.layers.MaxPool2D(pool_size=[2,2]),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer='adam',\n","              metrics=[\"accuracy\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdnAR5KzssZk"},"source":["Print the model summary"]},{"cell_type":"code","metadata":{"id":"ga-UGdspsslW"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11S83_J0MIqb"},"source":["Note that the number of parameters mostly depends on the output layers, indeed the parameter sharing techinique used by the 2D convolutional layers allows to significantly reduce the number of learnable weights.\n","Now we can train the model."]},{"cell_type":"code","metadata":{"id":"57aZ0KRGM7kY"},"source":["history = model.fit(X_train, y_train, epochs=10, batch_size=128,\n","                    validation_data=(X_valid, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xfPHQGs6M8AE"},"source":["Plot the loss and the accuracy trends for the training and validation set. Then, compute the result on the test set."]},{"cell_type":"code","metadata":{"id":"yVD4jB7ZMK5z"},"source":["def plot_loss(history):\n","  plt.figure(figsize=(10,6))\n","  plt.plot(history.epoch,history.history['loss'], label='loss')\n","  plt.plot(history.epoch,history.history['val_loss'],label='val_loss')\n","  plt.title('loss')\n","  plt.legend()\n","  \n","def plot_accuracy(history):\n","  plt.figure(figsize=(10,6))\n","  plt.plot(history.epoch,history.history['accuracy'],label='accuracy')\n","  plt.plot(history.epoch,history.history['val_accuracy'],label='val_accuracy')\n","  plt.title('accuracy')\n","  plt.legend()\n","  \n","plot_loss(history)\n","\n","plot_accuracy(history)\n","\n","scores = model.evaluate(X_test, y_test, verbose=2)\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5wOQymFYZjA"},"source":["###Visualize Weights\n","\n","An interesting thing to do is to visualize the learned weights for the convolutional layer. We have 32 kernels of size 3x3, we can just plot them as images, mapping the weight values to grayscale."]},{"cell_type":"code","metadata":{"id":"EXHiS8VyY6pg"},"source":["# Weights for the first convolutional layer\n","w0=model.get_weights()[0][:,:,0,:]\n","\n","# Normalize to range 0.0 - 1.0\n","w0-=np.min(w0)\n","w0/=np.max(w0)\n","\n","for r in range(4):\n","    for c in range(8):\n","        n=r*8+c\n","        plt.subplot(4, 8, n+1)\n","        plt.imshow(w0[:,:,n], interpolation='none')\n","        plt.axis('off')\n","        plt.gray()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsFQRbx3ZWtp"},"source":["They might be a bit hard to interpret, but it seems that the various filters have learned to detect various corners and edges."]},{"cell_type":"markdown","metadata":{"id":"PWQrBgoJdMxX"},"source":["### [TO COMPLETE] Deep CNN\n","Let's consider a deeper model, more precily in this exercise we consider a model composed of:\n","* One 2D convolutional layer with kernel size 3x3 and 32 output filters/features, that use ReLu activation function\n","* a Max Pooling layer (2D) of size 2x2 \n","* One 2D convolutional layer with kernel size 2x2 and 16 output filters/features, that use ReLu activation function\n","* a Max Pooling layer (2D) of size 2x2\n","* a Flatten layer\n","* a final Dense layer with 10 output neurons (one per class), and with the \"softmax\" activation function\n"]},{"cell_type":"code","metadata":{"id":"LKnSERQYdz0l"},"source":["model = keras.models.Sequential([\n","    keras.layers.Conv2D(filters=32, kernel_size=[3,3], activation='relu', input_shape=[32, 32,3]),\n","    keras.layers.MaxPool2D(pool_size=[2,2]),\n","    keras.layers.Conv2D(filters=16, kernel_size=[2,2], activation='relu'),\n","    keras.layers.MaxPool2D(pool_size=(2,2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","  ])\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=\"adam\",\n","              metrics=[\"accuracy\"])\n","  \n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NiRhA8wzd-Pq"},"source":["[TO COMPLETE] Explain in this cell: \n","\n","1.   how the number of parameters on each of the two Conv2D layers is determined;\n","2.   the reasons why the two considered convolutional layers have a different number of parameters.\n","\n","Answers:\n","\n","\n","1.   [TO COMPLETE] Answer to question 1\n","2.   [TO COMPLETE] Answer to question 2"]},{"cell_type":"markdown","metadata":{"id":"2PWM2NOKH_0m"},"source":["Let's now train our deep CNN."]},{"cell_type":"code","metadata":{"id":"RQASukcCe37M"},"source":["history = model.fit(X_train, y_train, epochs=10, batch_size=128,\n","                  validation_data=(X_valid, y_valid))\n","\n","plot_loss(history)\n","plot_accuracy(history)\n","\n","scores = model.evaluate(X_test, y_test, verbose=2)\n","print(\" %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","print(\"----------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-bOYmnXgZXi4"},"source":["## [TO COMPLETE] Exercise 3.2: Develop a better CNN\n","Let's develop a network that performs better than the very simple one above. This exercise aims to explore how much the various hyper-parameters influence the classification capability of the model. \n","\n","**[TO COMPLETE]**: Your task is to modify some of the hyper-parameters of the previous exercise's network and compare the results. At least one of the models you try should have an improvement in the test set results (generalization) over the result of the model used in the previous exercise.\n","In the cell below report only the code of the **best model** that you can find. In addtion, print out its result on the test set, and plot the accuracy and the loss trends in the notebook you return.\n","Moreover, for each setup you test, analyze and discuss the obtained results briefly in the last cells at the bottom.\n","\n","Hint: Each reparameterization should change a different aspect in the network, while the rest of the parameters would stay the same. \n","Example parameters to try to change (we suggest to test at least one re-parametrization for each of these categories):\n","\n","*    number of layers or neurons or filters dimension\n","*   activation functions\n","*   epochs\n","*   batch sizes\n","*   optimizer, see TensorFlow documentation on [optimizers](https://https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n","*   max-pooling on/off on certain layers, or pool size\n","\n","For what concerns the optimizer, as you can see in the 'compile' method [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) is it possible to pass as 'optimizer ' attribute's value a string (the name of optimizer) or an optimizer instance.\n","\n","Notice that changing the final layer's softmax activation plus the categorical_crossentropy loss requires some consideration. Don't do it unless you have a good plan."]},{"cell_type":"code","metadata":{"id":"N6ntGaFlkIBP"},"source":["#[TO COMPLETE]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nlE10XIjAid"},"source":["### [TO COMPLETE] Example of tests discussion\n","The best model that I found ...[TO COMPLETE]\n","\n","The achieved accuracy in the test set is ...[TO COMPLETE]\n","\n","Discussion:\n","[TO COMPLETE]"]},{"cell_type":"markdown","metadata":{"id":"4sj0soo3bRIs"},"source":["Besides, I tested also other models: \n","* [TO COMPLETE]\n","* ..\n","\n","\n","Discussion:\n","[TO COMPLETE]"]}]}